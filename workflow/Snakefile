# import config
# -----------------------------------------------------------------
configfile: "config/config.yaml"

# define variables
# ---------------------------------------------------------------
from pathlib import Path

samples = [
    x.name.removesuffix(config['R1_suffix']) for x in
    Path(config['sample_reads_folder']).glob("*"+config['R1_suffix'])
]

results = Path(config['output_directory'])

# include external modules
# -----------------------------------------------------------------------------------
module snp_eff_annotation:
    snakefile:
        github("simkin-bioinformatics/snp_eff_annotation", path = "/workflow/Snakefile", tag = '0.1')
        # "/Users/charlie/snp_eff_annotation/workflow/Snakefile"
    config: config

use rule * from snp_eff_annotation exclude copy_config as snpeff_*

use rule run_snp_eff from snp_eff_annotation as snpeff_run_snp_eff with:
    input:
        snp_eff_config = results / "snpEff_processing" / "snpEff.config",
        snp_eff_database = results / "snpEff_processing"/ "data" / config['genome_database_name'] / "sequence.bin",
        merged_vcf = results / 'genotyped_cohort.vcf.gz',

# Rules
# ----------------------------------------------------------------------------------------
include: "rules/create_indices.smk"
include: "rules/align_reads.smk"

rule all:
    input:
        rules.snpeff_all.input,
        copied_config = results / "config" / "config.yaml",
        copied_targets_tsv = results / "config" / Path(config['targets_tsv']).name,
    default_target: True

rule copy_config:
    input:
        config = "config/config.yaml",
        targets_tsv = config['targets_tsv']
    output:
        config = results / "config" / "config.yaml",
        targets_tsv = results / "config" / Path(config['targets_tsv']).name,
    shell:
        "rsync -a {input.config} {output.config} && "
        "rsync -a {input.targets_tsv} {output.targets_tsv}"

rule create_variant_arguments_file:
    input:
        called_haplotypes = expand(results / "temp" / "called_haplotypes" / "{sample}.g.vcf.gz", sample = samples),
    output:
        variant_arguments_file = results / "temp" / "consolidate_vcf_args.txt"
    run:
        with open(output.variant_arguments_file, 'w') as out:
            for variant in input.called_haplotypes:
                out.write(f"--variant {variant}\n")


rule consolidate_gVCFs:
# there is an alternate method using gatk GenomicsDBImport but here we will use gatk CombineGVCFs
# the other method is probably faster for very large datasets
    input:
        variant_arguments_file = results / "temp" / "consolidate_vcf_args.txt",
        ref_genome = copied_ref_genome,
    output:
        called_merged_haplotypes = results / "temp" / "called_haplotypes_merged.vcf.gz",
    shell:
        # gvcfs=({input.called_haplotypes})
        '''
         pixi run gatk CombineGVCFs \
           --R {input.ref_genome} \
           --arguments_file {input.variant_arguments_file} \
           -O {output.called_merged_haplotypes}
        '''

rule joint_genotyping_general:
    input:
        ref_genome = copied_ref_genome,
        called_merged_haplotypes = results / "temp" / "called_haplotypes_merged.vcf.gz",
        targets_vcf = results / "temp" / "targets.vcf"
    output:
        genotyped_cohort = results / 'genotyped_cohort.vcf.gz'
    shell:
        '''
        pixi run gatk GenotypeGVCFs \
            -R {input.ref_genome} \
            -V {input.called_merged_haplotypes} \
            -O {output.genotyped_cohort} \
            --force-output-intervals {input.targets_vcf}
        '''
